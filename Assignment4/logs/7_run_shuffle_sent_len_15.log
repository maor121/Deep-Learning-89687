less overfitting, gets to 80%

/home/maor16-04/Devl/git/deep-article-github/venv/bin/python /home/maor16-04/Devl/git/Deep-Learning-89687/Assignment4/code/train.py
/home/maor16-04/Devl/git/deep-article-github/venv/local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
/home/maor16-04/Devl/git/Deep-Learning-89687/Assignment4/code/model.py:54: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  prob1 = F.softmax(score1.view(-1, targets_sent_len)).view(-1, source_sent_len, targets_sent_len)
/home/maor16-04/Devl/git/Deep-Learning-89687/Assignment4/code/model.py:60: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  prob2 = F.softmax(score2.view(-1, source_sent_len)).view(-1, targets_sent_len, source_sent_len)
/home/maor16-04/Devl/git/Deep-Learning-89687/Assignment4/code/model.py:93: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  log_prob = self.log_prob(h)
[1, 10584] loss: 0.888, epoch time: 32.820
Dev: loss: 0.841, acc: 64.231 %
[2, 10584] loss: 0.709, epoch time: 29.100
Dev: loss: 0.733, acc: 72.462 %
[3, 10584] loss: 0.616, epoch time: 29.104
Dev: loss: 0.686, acc: 75.765 %
[4, 10584] loss: 0.571, epoch time: 29.209
Dev: loss: 0.623, acc: 77.116 %
[5, 10584] loss: 0.542, epoch time: 29.691
Dev: loss: 0.592, acc: 78.437 %
[6, 10584] loss: 0.519, epoch time: 29.735
Dev: loss: 0.583, acc: 78.752 %
[7, 10584] loss: 0.500, epoch time: 29.902
Dev: loss: 0.582, acc: 79.199 %
[8, 10584] loss: 0.485, epoch time: 29.484
Dev: loss: 0.566, acc: 79.362 %
[9, 10584] loss: 0.471, epoch time: 29.412
Dev: loss: 0.574, acc: 79.728 %
